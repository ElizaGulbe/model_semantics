{
  "activation": "relu",
  "batch_size": 128,
  "dropout_rate": 0.0,
  "hidden_sizes": [
    128,
    64
  ],
  "lr": 1e-05,
  "num_epochs": 59,
  "optimizer": "Adam",
  "postive_percentage": 0.6
}